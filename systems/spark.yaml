name: Spark
version: 51
path: /home/bhaynes/research/spark/
instrumentation:
  classPaths:
    - assembly/target/scala-2.11/spark-assembly-2.0.0-SNAPSHOT-hadoop2.6.0.jar
    # Must come after the main Spark jar
    - jars/org/apache/hadoop/hadoop-common/2.6.0/hadoop-common-2.6.0.jar
    - jars/org/apache/hadoop/hadoop-client/2.6.0/hadoop-client-2.6.0.jar
    - jars/commons-logging/commons-logging/1.2/commons-logging-1.2.jar
    - jars/commons-lang/commons-lang/2.6/commons-lang-2.6.jar
  commands: .*spark/core.*org.apache.spark.FileSuite.*
  classes: .*Runner.*
optimization:
  classPaths:
    - assembly/target/scala-2.11/spark-assembly-2.0.0-SNAPSHOT-hadoop2.6.0.jar
    - jars/org/apache/hadoop/hadoop-common/2.6.0/hadoop-common-2.6.0.jar
    - jars/org/apache/hadoop/hadoop-mapreduce-client-core/2.6.0/hadoop-mapreduce-client-core-2.6.0.jar
    #- recurse:jars/*
datapipe:
  import: build/mvn -Pyarn -Phadoop-2.6 -Dhadoop.version=2.6.0 -pl sql/core -am -q test -DwildcardSuites=org.apache.spark.FileSuite -Dtest=none -Dmaven.repo.local=/home/bhaynes/research/spark/jars -Dmaven.compile.fork=true -Dmaven.junit.fork=true -Denforcer.skip=true --offline
  export: build/mvn -Pyarn -Phadoop-2.6 -Dhadoop.version=2.6.0 -pl sql/core -am -q test -DwildcardSuites=org.apache.spark.FileSuite -Dtest=none -Dmaven.repo.local=/home/bhaynes/research/spark/jars -Dmaven.compile.fork=true -Dmaven.junit.fork=true -Denforcer.skip=true --offline
  verify: build/mvn -Pyarn -Phadoop-2.6 -Dhadoop.version=2.6.0 -pl sql/core -am -q test -DwildcardSuites=org.apache.spark.FileSuite -Dtest=none -Dmaven.repo.local=/home/bhaynes/research/spark/jars -Dmaven.compile.fork=true -Dmaven.junit.fork=true -Denforcer.skip=true --offline
